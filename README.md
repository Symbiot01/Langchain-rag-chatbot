# ğŸ§  RAG Chatbot (Groq + LangChain)

This is a Retrieval-Augmented Generation (RAG) chatbot built using [LangChain](https://www.langchain.com/), [Groq API](https://console.groq.com/), and [Streamlit](https://streamlit.io/). The chatbot can answer questions based solely on the contents of a `.txt` document using semantic search and an LLM backend (Groq).

## ğŸ”§ Features

-  Loads and splits a text document into semantic chunks.
-  Stores embeddings using ChromaDB with `BAAI/bge-base-en-v1.5`.
-  Uses Groq's LLMs (e.g., `llama3-8b-8192`) via `langchain-groq`.
-  Implements RetrievalQA with context-aware prompts.
-  Built-in Streamlit interface for interactive querying.
-  Source document traceability for every answer.

---

## ğŸ—‚ï¸ Project Structure

```

ğŸ“ langchain-chatbot/
â”‚
â”œâ”€â”€ config.py              # API keys and config variables
â”œâ”€â”€ rag\_pipeline.py        # Document loader, vector store setup, and RAG chain
â”œâ”€â”€ app.py                 # Streamlit app for user interaction
â”œâ”€â”€ data.txt               # Your text knowledge base
â”œâ”€â”€ chroma/                # Chroma vector store persistence directory
â””â”€â”€ README.md              # This file

````

---

## âš™ï¸ Installation

### 1. Clone the repository

```bash
git clone https://github.com/SudoAnxu/Langchain-RAG-Chatbot.git
cd Langchain-RAG-Chatbot
````

### 2. Create a virtual environment

```bash
python -m venv myenv
source myenv/bin/activate  # On Windows: myenv\Scripts\activate
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

You can generate `requirements.txt` using:

```bash
pip freeze > requirements.txt
```

---

## ğŸ”‘ Configuration

Create a `config.py` file in the root directory with the following:

```python
# config.py
GROQ_API_KEY = "your-groq-api-key"
LLM_MODEL = "llama3-8b-8192"  # or any supported Groq model
CHROMA_DIR = "chroma"
DATA_FILE = "data.txt"
```

---

## ğŸš€ Running the App

Make sure `data.txt` contains your source knowledge. Then launch the app:

```bash
streamlit run app.py
```

Visit `http://localhost:8501` in your browser.

---

## ğŸ§ª Example Query

```text
ğŸ’¬ Ask a question based on the document:
> What is the purpose of this document?

âœ… Answer:
> [The answer based strictly on the context]

ğŸ“„ Source Documents:
> [Shows chunks that answer was based on]
```

---

## ğŸ“Œ Notes

* The chatbot will **only answer questions using the provided context** from `data.txt`.
* If the answer is not found, it will respond:

  > *"I'm sorry, the information is not available in the provided context."*

---

## ğŸ“ƒ License

[MIT License](./LICENSE)

---

## âœ¨ Acknowledgments

* [LangChain](https://docs.langchain.com/)
* [Groq](https://groq.com/)
* [FastEmbed](https://github.com/lazymatrix/fastembed)
* [Streamlit](https://streamlit.io/)

---

## ğŸ™‹â€â™‚ï¸ Author

**Priyangshu Karmakar**
*AI Developer & ML Enthusiast*
GitHub: [@SudoAnxu](https://github.com/SudoAnxu)

```

